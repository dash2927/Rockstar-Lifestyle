{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"shell_port\": 60356,\n",
      "  \"iopub_port\": 60357,\n",
      "  \"stdin_port\": 60358,\n",
      "  \"control_port\": 60359,\n",
      "  \"hb_port\": 60360,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"a6b35052-53116a7be73d9a857566a564\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-e1c69b61-f921-47d3-972c-f1485e006ebb.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "     <img src=\"https://raw.githubusercontent.com/hhelmbre/Rockstar-Lifestyle/master/doc/Logo.png\" width=\"19%\" align=\"left\">\n",
    " \n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "# Neural Network Using Python\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The folling jupyter notebook will use neural networks in order to get quantifiable data for given images. It uses the neuralnet.py python file and imcrop.py image manipulation python file\n",
    "\n",
    "---\n",
    "\n",
    "The following functions will be used:\n",
    "\n",
    "* neuralnet( dataset = [], NN_settings = None, train = False, save_settings = True, print_acc = False)\n",
    "    * Description: This function is a wrapper function that will use a neural network in order to best estimate the protein count of the input images. The solver used in this neural network is L-BFGS which is a quasi-Newton method that is theoretically and experimentally verified to have a faster convergence and works well with low-dimensional input. L-BFGS does not work well in other settings because of its high memory requirement and lack of use of minibatches. There are other methods that can be tried (Adam, SGD BatchNorm , Adadelta, Adagrad), but L-BFGS was the best choice for this application and for the time constraint given in producing this package.\n",
    "    * Parameters: \n",
    "    \n",
    "        - dataset: dataset to use neural network on\n",
    "        - NN_settings: classifier data\n",
    "        - train: decide on whether to train or test\n",
    "        - save_settings: decide on whether to save classifier data to 'data' folder\n",
    "        - print_acc: passes bool to accuracy() to tell function to print accuracy\n",
    "    \n",
    "    * Output:\n",
    "        - count: The counts of the input dataset\n",
    "    \n",
    "* accuracy( test_x, test_y, classifier, output = False)\n",
    "    * Description: This function checks the accuracy of the neural network by sending testing data through the classifier and outputing the accuracy\n",
    "    * Parameters: \n",
    "    \n",
    "        - test_x: testing data\n",
    "        - test_y: answered data\n",
    "        - classifier: classifier object set by MLPClassifier\n",
    "        - output: boolean operator to determine whether to output info or not\n",
    "\n",
    "    * Output:\n",
    "        - acc: accuracy of the neural network\n",
    "    \n",
    "* __crop(td)\n",
    "    * Description: This private function for imCrop() crops an image attached to object td based on its applied resolution\n",
    "    * Parameters: \n",
    "    \n",
    "        - td : object : tileData() object containing required data\n",
    "    \n",
    "    * Output:\n",
    "        - img_stack : np.uint16 : (n, res_x, res_y) array of n stacks of cropped images\n",
    "    \n",
    "* stackLoad(path = '', file = '')\n",
    "    * Description: This function loads the given cropped stacked image into a numpy arrays\n",
    "    * Parameters: \n",
    "    \n",
    "        - path: str : String of path of file in the form of r\"C:/.../.../\"\n",
    "        - file: str : String of file name\n",
    "    \n",
    "    * Output:\n",
    "        - An (n, res_x, res_y) array of n stacks of cropped images\n",
    "\n",
    "* stackMRH(stacked_img)\n",
    "    * Description: This function loads the given cropped stacked image into a numpy arrays\n",
    "    * Parameters: \n",
    "    \n",
    "        - stacked_img : a 3d array containing all stacked images\n",
    "    \n",
    "    * Output:\n",
    "        - objlist : an object array containing descriptors for every cropped image\n",
    "\n",
    "The following objects will be used:\n",
    "\n",
    "* imgID()\n",
    "    * Description: Descriptor object for given image\n",
    "    * Contains:\n",
    "        - name : dict of the image# in the crop\n",
    "        - data : image data\n",
    "        - MRH : Multi Resolution Histogram data for image\n",
    "        - GB : Gaussian blur data for image\n",
    "        - bin_list : bin list for corresponding MRH\n",
    "        - count : number of objects in image\n",
    "    \n",
    "* tileData()\n",
    "    * Description: Identifier for ever tile crop for later ease of use in stacking\n",
    "    * Contains:\n",
    "        - im_path : string of image path given by user\n",
    "        - res : resolution given by user\n",
    "        - Data : image data from crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_settings = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object=5, black=6\n"
     ]
    }
   ],
   "source": [
    "obj_normalized = 5\n",
    "black = 6\n",
    "print('object=' + \n",
    "\t\t\t\t str(obj_normalized) + \n",
    "\t\t\t\t ', black=' + \n",
    "\t\t\t\t str(black))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: File saved does not end in '.dat', will have problems reading. Automatically renaming to 'hello'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "warnings.warn(\"File saved does not end in '.dat', will \"\\\n",
    "\t\t\t\t\t \"have problems reading. Automatically \"\\\n",
    "\t\t\t\t\t \"renaming to '{}'.\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
